#!/usr/bin/env python3
"""
Gerar Gr√°ficos - ProjetoK
Script unificado para gera√ß√£o de relat√≥rio visual.
Gera APENAS o relat√≥rio final com m√©tricas comparativas de Go vs Python.
"""

import json
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
from pathlib import Path
import glob
from datetime import datetime
import time

# Configura√ß√£o do matplotlib para melhor apar√™ncia
plt.style.use('seaborn-v0_8')
plt.rcParams['figure.figsize'] = (20, 12)
plt.rcParams['font.size'] = 11

# Obter caminho absoluto da raiz do projeto
SCRIPT_DIR = Path(__file__).parent.absolute()
PROJECT_ROOT = SCRIPT_DIR.parent.parent  # src/testes -> src -> ProjetoK
RESULTADOS_DIR = PROJECT_ROOT / "resultados"
GRAFICOS_DIR = RESULTADOS_DIR / "graficos"
RELATORIOS_DIR = RESULTADOS_DIR / "relatorios"

class GeradorGraficos:
    def __init__(self):
        # Criar diret√≥rios se n√£o existirem
        RESULTADOS_DIR.mkdir(exist_ok=True)
        GRAFICOS_DIR.mkdir(exist_ok=True)
        RELATORIOS_DIR.mkdir(exist_ok=True)
        
        self.df_dados = None  # DataFrame principal com todos os dados
        
        print(f"üìÅ Diret√≥rio de resultados: {RESULTADOS_DIR}")
        print(f"üìÅ Diret√≥rio de gr√°ficos: {GRAFICOS_DIR}")
        print(f"üìÅ Diret√≥rio de relat√≥rios: {RELATORIOS_DIR}")
        
        self._carregar_dados_csv()
    
    def _carregar_dados_csv(self):
        """Carregar dados do relat√≥rio estat√≠stico CSV"""
        print("üìÇ Carregando dados do relat√≥rio estat√≠stico...")
        
        csv_file = RELATORIOS_DIR / "relatorio_estatistico.csv"
        
        if csv_file.exists():
            try:
                self.df_dados = pd.read_csv(csv_file, encoding='utf-8')
                print(f"‚úÖ Carregado: {csv_file.name}")
                print(f"üìä Total de execu√ß√µes: {len(self.df_dados)}")
                
                # Exibir resumo por linguagem
                if 'linguagem' in self.df_dados.columns:
                    resumo = self.df_dados['linguagem'].value_counts()
                    for linguagem, count in resumo.items():
                        print(f"   üìä {linguagem}: {count} execu√ß√µes")
                
                # Verificar e remover outliers automaticamente
                self._processar_outliers()
                
            except Exception as e:
                print(f"‚ùå Erro ao carregar CSV: {e}")
                print("‚ö†Ô∏è  Tentando carregar dados dos JSONs como fallback...")
                self._carregar_dados_json_fallback()
        else:
            print("‚ö†Ô∏è  Arquivo relatorio_estatistico.csv n√£o encontrado")
            print("üìù Gerando relat√≥rio estat√≠stico primeiro...")
            self._carregar_dados_json_fallback()
            if self.df_dados is not None:
                self._salvar_csv()
    
    def _processar_outliers(self):
        """Identificar e opcionalmente remover outliers dos dados"""
        if self.df_dados is None or len(self.df_dados) == 0:
            return
        
        print("üßπ Analisando outliers...")
        
        # Identificar outliers por m√©trica usando IQR
        metricas = ['throughput', 'latencia_media', 'tempo_execucao']
        outliers_total = set()
        
        for metrica in metricas:
            if metrica in self.df_dados.columns:
                # Calcular outliers por linguagem separadamente
                for linguagem in self.df_dados['linguagem'].unique():
                    dados_linguagem = self.df_dados[self.df_dados['linguagem'] == linguagem]
                    
                    Q1 = dados_linguagem[metrica].quantile(0.25)
                    Q3 = dados_linguagem[metrica].quantile(0.75)
                    IQR = Q3 - Q1
                    
                    # Outliers moderados (1.5 * IQR)
                    limite_inferior = Q1 - 1.5 * IQR
                    limite_superior = Q3 + 1.5 * IQR
                    
                    outliers_metrica = dados_linguagem[
                        (dados_linguagem[metrica] < limite_inferior) | 
                        (dados_linguagem[metrica] > limite_superior)
                    ].index
                    
                    outliers_total.update(outliers_metrica)
                    
                    if len(outliers_metrica) > 0:
                        print(f"   üìä {linguagem} - {metrica}: {len(outliers_metrica)} outliers identificados")
        
        if outliers_total:
            print(f"üîç Total de outliers encontrados: {len(outliers_total)} de {len(self.df_dados)} registros")
            print(f"üìä Percentual de outliers: {len(outliers_total)/len(self.df_dados)*100:.1f}%")
            
            # Remover outliers apenas se forem menos de 10% dos dados
            if len(outliers_total) / len(self.df_dados) < 0.10:
                self.df_dados = self.df_dados.drop(index=outliers_total)
                print(f"‚úÖ Outliers removidos. Dados restantes: {len(self.df_dados)}")
            else:
                print("‚ö†Ô∏è  Muitos outliers encontrados (>10%). Mantendo todos os dados.")
        else:
            print("‚úÖ Nenhum outlier significativo encontrado")
    
    def _carregar_dados_json_fallback(self):
        """Carregar dados dos JSONs como fallback"""
        print("üìÇ Carregando dados dos arquivos JSON...")
        
        dados_go = []
        dados_python = []
        
        # Procurar arquivos de resultados Go
        arquivos_go = glob.glob(str(RELATORIOS_DIR / "resultados_go*.json"))
        for arquivo in arquivos_go:
            try:
                with open(arquivo, 'r', encoding='utf-8') as f:
                    dados = json.load(f)
                    if 'resultados' in dados:
                        dados_go.extend(dados['resultados'])
                    elif isinstance(dados, list):
                        dados_go.extend(dados)
                print(f"‚úÖ Carregado: {Path(arquivo).name}")
            except Exception as e:
                print(f"‚ùå Erro ao carregar {arquivo}: {e}")
        
        # Procurar arquivos de resultados Python
        arquivos_python = glob.glob(str(RELATORIOS_DIR / "resultados_python*.json"))
        for arquivo in arquivos_python:
            try:
                with open(arquivo, 'r', encoding='utf-8') as f:
                    dados = json.load(f)
                    if 'resultados' in dados:
                        dados_python.extend(dados['resultados'])
                    elif isinstance(dados, list):
                        dados_python.extend(dados)
                print(f"‚úÖ Carregado: {Path(arquivo).name}")
            except Exception as e:
                print(f"‚ùå Erro ao carregar {arquivo}: {e}")
        
        # Converter para DataFrame consolidado
        dados_consolidados = []
        
        for dado in dados_go:
            dados_consolidados.append({
                'linguagem': 'Go',
                'timestamp': dado.get('timestamp', ''),
                'ambiente': dado.get('ambiente', 'kubernetes'),
                'num_servidores': dado.get('num_servidores', 0),
                'num_clientes': dado.get('num_clientes', 0),
                'num_mensagens': dado.get('num_mensagens', 0),
                'repeticao': dado.get('repeticao', 0),
                'tempo_execucao': dado.get('tempo_execucao', 0),
                'total_mensagens': dado.get('total_mensagens', 0),
                'throughput': dado.get('throughput', 0),
                'latencia_media': dado.get('latencia_media', 0)
            })
        
        for dado in dados_python:
            dados_consolidados.append({
                'linguagem': 'Python',
                'timestamp': dado.get('timestamp', ''),
                'ambiente': dado.get('ambiente', 'kubernetes'),
                'num_servidores': dado.get('num_servidores', 0),
                'num_clientes': dado.get('num_clientes', 0),
                'num_mensagens': dado.get('num_mensagens', 0),
                'repeticao': dado.get('repeticao', 0),
                'tempo_execucao': dado.get('tempo_execucao', 0),
                'total_mensagens': dado.get('total_mensagens', 0),
                'throughput': dado.get('throughput', 0),
                'latencia_media': dado.get('latencia_media', 0)
            })
        
        if dados_consolidados:
            self.df_dados = pd.DataFrame(dados_consolidados)
            print(f"üìä Total de execu√ß√µes carregadas: {len(self.df_dados)}")
        else:
            print("‚ùå Nenhum dado encontrado")
    
    def _salvar_csv(self):
        """Salvar dados consolidados em CSV"""
        if self.df_dados is not None and len(self.df_dados) > 0:
            csv_file = RELATORIOS_DIR / "relatorio_estatistico.csv"
            self.df_dados.to_csv(csv_file, index=False, encoding='utf-8')
            print(f"‚úÖ Relat√≥rio CSV salvo: {csv_file}")
    
    def _filtrar_dados(self, linguagem=None):
        """Filtrar dados por linguagem"""
        if self.df_dados is None:
            return pd.DataFrame()
        
        if linguagem:
            return self.df_dados[self.df_dados['linguagem'] == linguagem].copy()
        else:
            return self.df_dados.copy()
    

    
    # Fun√ß√£o √∫nica para gerar relat√≥rio final completo (gr√°fico de barras + 2 √°reas empilhadas)
    
    def gerar_relatorio_final_completo(self):
        """Gr√°fico Final: Barras + √Årea Empilhada em um √∫nico PNG com propor√ß√µes otimizadas"""
        if self.df_dados is None or len(self.df_dados) == 0:
            print("‚ö†Ô∏è  Nenhum dado dispon√≠vel para gerar relat√≥rio final")
            return
            
        df_go = self._filtrar_dados('Go')
        df_python = self._filtrar_dados('Python')
        
        if len(df_go) == 0 or len(df_python) == 0:
            print("‚ö†Ô∏è  Dados insuficientes para relat√≥rio final")
            return
        
        # Criar figura com propor√ß√µes otimizadas
        fig = plt.figure(figsize=(20, 12))
        
        # Layout melhorado: 3 linhas
        # Linha 1: Gr√°fico de barras (40% da altura)
        # Linhas 2-3: √Årea empilhada (60% da altura)
        
        ax_barras = plt.subplot2grid((5, 2), (0, 0), colspan=2, rowspan=2)  # 2/5 = 40%
        ax_go = plt.subplot2grid((5, 2), (2, 0), rowspan=3)                 # 3/5 = 60%
        ax_python = plt.subplot2grid((5, 2), (2, 1), rowspan=3)             # 3/5 = 60%
        
        # ========== GR√ÅFICO DE BARRAS (TOPO) ==========
        try:
            # Calcular m√©tricas agregadas
            metricas_go = {
                'Throughput\nM√©dio': df_go['throughput'].mean(),
                'Throughput\nM√°ximo': df_go['throughput'].max(),
                'Lat√™ncia\nM√©dia': df_go['latencia_media'].mean(),
                'Tempo\nExecu√ß√£o': df_go['tempo_execucao'].mean(),
                'Efici√™ncia\n(msg/s/serv)': (df_go['throughput'] / df_go['num_servidores']).mean()
            }
            
            metricas_python = {
                'Throughput\nM√©dio': df_python['throughput'].mean(),
                'Throughput\nM√°ximo': df_python['throughput'].max(),
                'Lat√™ncia\nM√©dia': df_python['latencia_media'].mean(),
                'Tempo\nExecu√ß√£o': df_python['tempo_execucao'].mean(),
                'Efici√™ncia\n(msg/s/serv)': (df_python['throughput'] / df_python['num_servidores']).mean()
            }
            
            x = np.arange(len(metricas_go))
            width = 0.35
            
            valores_go = list(metricas_go.values())
            valores_python = list(metricas_python.values())
            labels = list(metricas_go.keys())
            
            # Normalizar lat√™ncia e tempo
            valores_go_norm = valores_go.copy()
            valores_python_norm = valores_python.copy()
            
            valores_go_norm[2] = 1000 / valores_go[2] if valores_go[2] > 0 else 0
            valores_python_norm[2] = 1000 / valores_python[2] if valores_python[2] > 0 else 0
            valores_go_norm[3] = 100 / valores_go[3] if valores_go[3] > 0 else 0
            valores_python_norm[3] = 100 / valores_python[3] if valores_python[3] > 0 else 0
            
            labels[2] = 'Velocidade\n(1/lat√™ncia)'
            labels[3] = 'Velocidade\n(1/tempo)'
            
            # Cores atualizadas: Go azul escuro, Python amarelo
            bars1 = ax_barras.bar(x - width/2, valores_go_norm, width, label='Go', 
                                 color='#1f4e79', alpha=0.9, edgecolor='black', linewidth=0.8)
            bars2 = ax_barras.bar(x + width/2, valores_python_norm, width, label='Python', 
                                 color='#ffcc00', alpha=0.9, edgecolor='black', linewidth=0.8)
            
            # Adicionar valores nas barras
            for i, (bar1, bar2) in enumerate(zip(bars1, bars2)):
                height1 = bar1.get_height()
                height2 = bar2.get_height()
                
                if i == 2:  # Lat√™ncia
                    ax_barras.text(bar1.get_x() + bar1.get_width()/2., height1,
                                  f'{valores_go[i]:.1f}ms', ha='center', va='bottom', fontsize=10, fontweight='bold')
                    ax_barras.text(bar2.get_x() + bar2.get_width()/2., height2,
                                  f'{valores_python[i]:.1f}ms', ha='center', va='bottom', fontsize=10, fontweight='bold')
                elif i == 3:  # Tempo
                    ax_barras.text(bar1.get_x() + bar1.get_width()/2., height1,
                                  f'{valores_go[i]:.1f}s', ha='center', va='bottom', fontsize=10, fontweight='bold')
                    ax_barras.text(bar2.get_x() + bar2.get_width()/2., height2,
                                  f'{valores_python[i]:.1f}s', ha='center', va='bottom', fontsize=10, fontweight='bold')
                else:
                    ax_barras.text(bar1.get_x() + bar1.get_width()/2., height1,
                                  f'{valores_go[i]:,.0f}', ha='center', va='bottom', fontsize=10, fontweight='bold')
                    ax_barras.text(bar2.get_x() + bar2.get_width()/2., height2,
                                  f'{valores_python[i]:,.0f}', ha='center', va='bottom', fontsize=10, fontweight='bold')
            
            ax_barras.set_ylabel('Valores (normalizados)', fontweight='bold', fontsize=12)
            ax_barras.set_title('Comparativo Go vs Python - M√©tricas de Performance', 
                               fontsize=16, fontweight='bold', pad=20)
            ax_barras.set_xticks(x)
            ax_barras.set_xticklabels(labels, fontsize=11, ha='center')
            ax_barras.legend(loc='upper right', fontsize=12, frameon=True, fancybox=True, shadow=True)
            ax_barras.grid(True, alpha=0.3, axis='y')
            
            # Vencedor com destaque verde
            score_go = sum(valores_go_norm)
            score_python = sum(valores_python_norm)
            vencedor = "Go" if score_go > score_python else "Python"
            ratio = max(score_go, score_python) / min(score_go, score_python)
            
            ax_barras.text(0.02, 0.95, f'Vencedor: {vencedor} ({ratio:.1f}x melhor)', 
                          transform=ax_barras.transAxes, fontsize=14, fontweight='bold',
                          bbox=dict(boxstyle="round,pad=0.4", facecolor='#2e8b57', alpha=0.9, edgecolor='black'),
                          verticalalignment='top', color='white')
            
        except Exception as e:
            ax_barras.text(0.5, 0.5, f'Erro no gr√°fico de barras:\n{str(e)}', 
                          ha='center', va='center', transform=ax_barras.transAxes, fontsize=12)
        
        # ========== GR√ÅFICOS DE √ÅREA EMPILHADA ==========
        
        def criar_area_empilhada_otimizada(df, ax, titulo, cores):
            try:
                pivot = df.groupby(['num_mensagens', 'num_servidores'])['throughput'].mean().unstack(fill_value=0)
                
                x = list(pivot.index)
                x_labels = [f'{int(val):,}' for val in x]
                
                areas_data = []
                labels_servidores = []
                
                for col in pivot.columns:
                    areas_data.append(pivot[col].values)
                    labels_servidores.append(f'{col} servidor{"es" if col > 1 else ""}')
                
                # √Årea empilhada com bordas
                polys = ax.stackplot(range(len(x)), *areas_data, 
                                   labels=labels_servidores,
                                   colors=cores, alpha=0.85, edgecolor='white', linewidth=0.5)
                
                # Linha total mais destacada
                total = pivot.sum(axis=1).values
                ax.plot(range(len(x)), total, 'k-', linewidth=3, alpha=0.9, 
                       label='Total', marker='o', markersize=6, markerfacecolor='white', 
                       markeredgecolor='black', markeredgewidth=2)
                
                ax.set_title(titulo, fontweight='bold', fontsize=14, pad=15)
                ax.set_xlabel('N√∫mero de Mensagens', fontsize=12, fontweight='bold')
                ax.set_ylabel('Throughput (msg/s)', fontsize=12, fontweight='bold')
                
                ax.set_xticks(range(len(x)))
                ax.set_xticklabels(x_labels, rotation=45, fontsize=10)
                
                # Valores no topo mais seletivos
                step = max(1, len(total) // 4)
                for i in range(0, len(total), step):
                    if total[i] > 0:
                        ax.text(i, total[i] + max(total)*0.03, f'{int(total[i]):,}', 
                               ha='center', va='bottom', fontweight='bold', fontsize=11,
                               bbox=dict(boxstyle="round,pad=0.2", facecolor='white', alpha=0.8))
                
                ax.legend(loc='upper left', fontsize=10, frameon=True, fancybox=True, shadow=True)
                ax.grid(True, alpha=0.3, axis='y')
                
                # Stats com destaque
                throughput_max = max(total)
                throughput_medio = np.mean(total)
                
                stats_text = f'M√°ximo: {int(throughput_max):,}\nM√©dia: {int(throughput_medio):,}'
                ax.text(0.98, 0.98, stats_text, transform=ax.transAxes, 
                       fontsize=11, fontweight='bold', verticalalignment='top', horizontalalignment='right',
                       bbox=dict(boxstyle="round,pad=0.3", facecolor='#f8f9fa', alpha=0.95, edgecolor='black'))
                
            except Exception as e:
                ax.text(0.5, 0.5, f'Erro:\n{str(e)}', ha='center', va='center', 
                       transform=ax.transAxes, fontsize=12)
        
        # Cores otimizadas
        cores_go = ['#0a1628', '#1f4e79', '#2e6da4', '#4a90e2', '#87ceeb']
        cores_python = ['#996633', '#cc8800', '#ffcc00', '#ffd700', '#fff8dc']
        
        # √Årea empilhada Go
        criar_area_empilhada_otimizada(df_go, ax_go, 'Go - Throughput Acumulado por Configura√ß√£o', cores_go)
        
        # √Årea empilhada Python
        criar_area_empilhada_otimizada(df_python, ax_python, 'Python - Throughput Acumulado por Configura√ß√£o', cores_python)
        
        # ========== LEGENDA GERAL OTIMIZADA ==========
        
        # C√≥digo para estat√≠sticas (removido da exibi√ß√£o)
        total_execucoes = len(self.df_dados)
        execucoes_go = len(df_go)
        execucoes_python = len(df_python)
        throughput_max_go = df_go['throughput'].max()
        throughput_max_python = df_python['throughput'].max()
        ratio_performance = throughput_max_go / throughput_max_python if throughput_max_python > 0 else 0
        
        # Sem legenda inferior global
        
        # Ajustar layout com propor√ß√µes otimizadas para evitar sobreposi√ß√£o
        plt.tight_layout()
        plt.subplots_adjust(top=0.95, bottom=0.12, left=0.08, right=0.96, 
                           hspace=0.8, wspace=0.2)
        
        arquivo_salvo = GRAFICOS_DIR / 'relatorio_final_completo.png'
        plt.savefig(arquivo_salvo, dpi=300, bbox_inches='tight',
                   facecolor='white', edgecolor='none')
        print(f"‚úÖ Relat√≥rio Final salvo: {arquivo_salvo.name}")
        plt.close()
        
        return arquivo_salvo

    def gerar_relatorio_resumo(self):
        """Gera um relat√≥rio resumido em formato de texto"""
        if self.df_dados is None or len(self.df_dados) == 0:
            print("‚ö†Ô∏è  Nenhum dado dispon√≠vel para gerar relat√≥rio resumo")
            return
            
        df_go = self._filtrar_dados('Go')
        df_python = self._filtrar_dados('Python')
        
        if len(df_go) == 0 or len(df_python) == 0:
            print("‚ö†Ô∏è  Dados insuficientes para relat√≥rio resumo")
            return
        
        # Calcular estat√≠sticas
        data_atual = datetime.now().strftime("%d/%m/%Y %H:%M:%S")
        
        # Estat√≠sticas Go
        total_execucoes_go = len(df_go)
        throughput_medio_go = df_go['throughput'].mean()
        throughput_max_go = df_go['throughput'].max()
        throughput_min_go = df_go['throughput'].min()
        latencia_media_go = df_go['latencia_media'].mean()
        latencia_max_go = df_go['latencia_media'].max()
        latencia_min_go = df_go['latencia_media'].min()
        
        # Estat√≠sticas Python
        total_execucoes_python = len(df_python)
        throughput_medio_python = df_python['throughput'].mean()
        throughput_max_python = df_python['throughput'].max()
        throughput_min_python = df_python['throughput'].min()
        latencia_media_python = df_python['latencia_media'].mean()
        latencia_max_python = df_python['latencia_media'].max()
        latencia_min_python = df_python['latencia_media'].min()
        
        # Comparativo
        diff_throughput = (throughput_medio_go / throughput_medio_python) * 100 - 100
        diff_latencia = (latencia_media_python / latencia_media_go) * 100 - 100
        
        # Gerar conte√∫do do relat√≥rio
        conteudo = f"""================================================================================
RESUMO EXECUTIVO - PROJETO K
================================================================================
Data de gera√ß√£o: {data_atual}

LINGUAGEM GO
----------------------------------------
Total de execu√ß√µes: {total_execucoes_go}
Throughput m√©dio: {throughput_medio_go:.2f} msg/s
Throughput m√°ximo: {throughput_max_go:.2f} msg/s
Throughput m√≠nimo: {throughput_min_go:.2f} msg/s
Lat√™ncia m√©dia: {latencia_media_go:.2f} ms
Lat√™ncia m√°xima: {latencia_max_go:.2f} ms
Lat√™ncia m√≠nima: {latencia_min_go:.2f} ms

LINGUAGEM PYTHON
----------------------------------------
Total de execu√ß√µes: {total_execucoes_python}
Throughput m√©dio: {throughput_medio_python:.2f} msg/s
Throughput m√°ximo: {throughput_max_python:.2f} msg/s
Throughput m√≠nimo: {throughput_min_python:.2f} msg/s
Lat√™ncia m√©dia: {latencia_media_python:.2f} ms
Lat√™ncia m√°xima: {latencia_max_python:.2f} ms
Lat√™ncia m√≠nima: {latencia_min_python:.2f} ms

COMPARATIVO
----------------------------------------
Diferen√ßa de throughput (Go vs Python): {diff_throughput:.2f}%
Diferen√ßa de lat√™ncia (Python vs Go): {diff_latencia:.2f}%"""
        
        # Salvar arquivo
        arquivo_resumo = RELATORIOS_DIR / "relatorio_resumo.txt"
        with open(arquivo_resumo, 'w', encoding='utf-8') as f:
            f.write(conteudo)
        
        print(f"‚úÖ Relat√≥rio resumo salvo: {arquivo_resumo}")
        return arquivo_resumo


def main():
    """Fun√ß√£o principal"""
    # Mostrar quanto tempo durou o processamento
    start_time = time.time()
    
    try:
        print("üé® Iniciando gera√ß√£o do relat√≥rio final...")
        
        gerador = GeradorGraficos()  # Dados j√° s√£o carregados no __init__
        
        print("\nüéØ Gerando Relat√≥rio Final Completo...")
        gerador.gerar_relatorio_final_completo()
        
        print("\nüéØ Gerando Relat√≥rio Resumo...")
        gerador.gerar_relatorio_resumo()
        
        print("\n" + "="*60)
        print(f"‚úÖ Relat√≥rios gerados com sucesso! ({time.time() - start_time:.1f} segundos)")
        print(f"üìÅ Gr√°ficos salvos em: {GRAFICOS_DIR}")
        print(f"üìÅ Relat√≥rios salvos em: {RELATORIOS_DIR}")
        print("\nüéØ ARQUIVOS GERADOS:")
        print("   üìã relatorio_final_completo.png (gr√°fico)")
        print("   üìã relatorio_resumo.txt (texto)")
        print("\nüí° Use estes arquivos para apresenta√ß√µes e relat√≥rios!")
        print("="*60)
        
    except Exception as e:
        print(f"‚ùå Erro durante execu√ß√£o: {e}")
        print(f"‚è±Ô∏è Tempo decorrido antes do erro: {time.time() - start_time:.1f} segundos")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
